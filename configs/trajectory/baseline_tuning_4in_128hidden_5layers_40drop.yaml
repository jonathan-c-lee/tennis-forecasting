name: baseline_tuning_4in_128hidden_5layers_40drop
frames_in: 4
frames_out: 15
layers: 5
hidden_size: 128
dropout: 0.4
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.03830171716801914
- 0.023822601792621023
- 0.023696901725122222
- 0.023498926863626198
- 0.023613173399626472
- 0.02351561448548311
- 0.02360604310201274
- 0.023373963012371535
- 0.023453514839028133
- 0.023265917877448195
- 0.023342304207660532
- 0.023355821044080786
- 0.023578028953461734
- 0.023583856227313293
- 0.02342183689046421
- 0.023473887347880706
- 0.023216842777199216
- 0.02322235873635904
- 0.023259950295826535
- 0.023436669490219636
- 0.023152808428822474
- 0.023369045652173185
- 0.023679742589592934
- 0.02342459056986335
- 0.02314480326287908
- 0.023157616893266453
- 0.023382549392588346
- 0.023285162784619097
- 0.023298027269818163
- 0.023374266071636
- 0.023369352172278327
- 0.02334250931708533
- 0.02328887565728323
- 0.02339159363857758
- 0.023427498998281397
- 0.023202957424484652
- 0.023520167020184023
- 0.023393662899364658
- 0.023272689040980222
- 0.023158358582467946
- 0.02332550869035868
- 0.023317275752807842
- 0.0233595752513703
- 0.02321469494038158
- 0.023362449519796137
- 0.0232836516160104
- 0.023376410643075718
- 0.023434517813133604
- 0.02331003588106897
- 0.023326941731351393
- 0.02317756055681794
- 0.023281877297034233
- 0.02324859146028757
- 0.023179756960383168
- 0.023373431675596003
- 0.023248655261632837
- 0.023388274807344983
- 0.023318071217264657
- 0.023351242282876262
- 0.023258692941363946
- 0.023313553256477104
- 0.02331931849964607
- 0.023444663376811847
- 0.023087998518697275
- 0.023296991064224715
- 0.02332748264580229
- 0.023350821980447682
- 0.02308918671383534
- 0.023252793852193854
- 0.02330282420195915
- 0.02328207409354272
- 0.023174943885317555
- 0.023132498272591166
- 0.023176983711712153
- 0.02339615777456834
- 0.023286063281566273
- 0.02316842030411885
- 0.02317429043030665
- 0.02349237000776662
- 0.023507719951463335
- 0.023166264050904616
- 0.02313312488021674
- 0.023339077347406634
- 0.02343152926797852
- 0.02316215714830675
- 0.023335929730056243
- 0.02327399455976707
- 0.023036065637881374
- 0.023187345928615995
- 0.023368172336047814
- 0.023194854987072355
- 0.023274566196365122
- 0.023176742464671902
- 0.023206403697438448
- 0.023156966462179466
- 0.023143361874476628
- 0.023275356176366776
- 0.023274792634226656
- 0.023183950280517708
- 0.023145424179088922
