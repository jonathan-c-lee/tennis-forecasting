name: baseline_tuning_4in_128hidden_2layers_0drop
frames_in: 4
frames_out: 15
layers: 2
hidden_size: 128
dropout: 0.0
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.03842343325600212
- 0.018592533241543505
- 0.014253041804710657
- 0.01282847615211834
- 0.012442873118238317
- 0.012313077145796499
- 0.012174568811638488
- 0.01140131922668697
- 0.011293352064159181
- 0.011188686750599263
- 0.01071630501659748
- 0.010242363639221883
- 0.00987749670367734
- 0.009208625567686042
- 0.008827294418473302
- 0.008552429461736738
- 0.008704712551179123
- 0.008024109205530013
- 0.008583393568793932
- 0.008175969813708906
- 0.007890478224941978
- 0.00803734409266416
- 0.008115031365535142
- 0.007782403115229106
- 0.007889946336271587
- 0.007758840470126382
- 0.007565240542415852
- 0.00784749975198029
- 0.007768894505491595
- 0.007614661376049489
- 0.007577289246528605
- 0.007573017557324083
- 0.007618697302668918
- 0.007558628635044083
- 0.007528468903246118
- 0.007578577990011301
- 0.007548423989871402
- 0.0075601869389230825
- 0.0074439521786975275
- 0.0074620909276015964
- 0.0072955700200924905
- 0.007399192332853506
- 0.007742504813466911
- 0.0073706764371398795
- 0.007673768752059083
- 0.007422819584148165
- 0.0074674057613276406
- 0.007276122400790085
- 0.007287968639974241
- 0.007318464745939882
- 0.007266537596782048
- 0.007278950948176192
- 0.0073099485196081206
- 0.007333005663513401
- 0.00728246620223846
- 0.0070771303683243416
- 0.00703266083067398
- 0.007030689421995187
- 0.006999153310410035
- 0.007148314618080119
- 0.007331466606967611
- 0.007061350929700298
- 0.007094639658146066
- 0.006988706688086192
- 0.007121093858631305
- 0.007018536668454791
- 0.007052928887675574
- 0.007006674113878866
- 0.007005421864443723
- 0.006919542632215185
- 0.007045497692385574
- 0.007131600197703566
- 0.0071014518832304965
- 0.007097352290365063
- 0.006968033212570496
- 0.007007929140035017
- 0.007000967521036481
- 0.0070620604020393924
- 0.0071090756179649885
- 0.0069229215050093185
- 0.006875336699095773
- 0.006992788226516159
- 0.006847299278978212
- 0.006883404459114428
- 0.0069433886465834985
- 0.0070023326559659135
- 0.007026126171335762
- 0.006953134465916657
- 0.0067694181875314246
- 0.006875414915819779
- 0.006879325981976258
- 0.006946693668946808
- 0.006975334080189098
- 0.0068014847160673434
- 0.006889677158108464
- 0.006795547195468788
- 0.006815525159860651
- 0.006885182957544371
- 0.006809787830498851
- 0.0067843426030451135
