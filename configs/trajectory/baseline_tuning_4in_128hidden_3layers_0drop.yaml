name: baseline_tuning_4in_128hidden_3layers_0drop
frames_in: 4
frames_out: 15
layers: 3
hidden_size: 128
dropout: 0.0
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.037107258529206856
- 0.020350904445405358
- 0.01766506145581787
- 0.01513794523284391
- 0.01362601201981306
- 0.01324076726342793
- 0.012760399507335674
- 0.012273765019612548
- 0.01197537225038733
- 0.011678281774813379
- 0.011493293442016031
- 0.011030238047012208
- 0.010702415288966378
- 0.009361880584217516
- 0.009271764265442337
- 0.008611939416301471
- 0.008578712730036105
- 0.008415756040011291
- 0.008327764660166001
- 0.007984877747977957
- 0.008259610842085548
- 0.008128961301006285
- 0.008014682576888137
- 0.007799045263249197
- 0.00791262256924385
- 0.007945947780239361
- 0.007679560727635284
- 0.007933569525908908
- 0.0077625538314474215
- 0.007524298216549702
- 0.007697166558815006
- 0.007838416068504253
- 0.007544533706005709
- 0.007522586445657559
- 0.007520034564314065
- 0.007457978425570476
- 0.007472259515643488
- 0.00751625380858227
- 0.0074802624912541586
- 0.007508691383042821
- 0.007352480716589425
- 0.00761721730462195
- 0.00747567066853797
- 0.0073254187763841065
- 0.007294027134776115
- 0.007278237595326371
- 0.007429585976089224
- 0.007257297439615668
- 0.007516771899881186
- 0.0074911533400738315
- 0.007210131337935174
- 0.007245858504586381
- 0.007113228802120796
- 0.007328303961980122
- 0.0073401651540656145
- 0.007324403887729586
- 0.007268515162537863
- 0.007449013227021989
- 0.007137046385280512
- 0.007217182829562161
- 0.007243009600328442
- 0.007094283979156135
- 0.007029984175101107
- 0.007067189577759968
- 0.007176271766240214
- 0.007072819454342495
- 0.0072060147081904205
- 0.007193404186608983
- 0.007146545593845256
- 0.0072536839195239695
- 0.007001193154051348
- 0.007153421735253047
- 0.007217607616136472
- 0.007132521744265601
- 0.007091046377073651
- 0.007031854834223603
- 0.007050353062143664
- 0.006964084962497891
- 0.007057941875156061
- 0.007206976367735568
- 0.007040842953655455
- 0.006931802203280874
- 0.0069746550224307514
- 0.007076873990166702
- 0.007065732957634293
- 0.007117757510485841
- 0.006947119024662692
- 0.00707480069939737
- 0.007128515401510177
- 0.007000202882207102
- 0.006903933573882153
- 0.0068806944254003926
- 0.006974983333759469
- 0.006891513185828556
- 0.006841488277401637
- 0.006859565538894615
- 0.0070094582739711545
- 0.006928148621946205
- 0.006986296591981325
- 0.006996001769432131
