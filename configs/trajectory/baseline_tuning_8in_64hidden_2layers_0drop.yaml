name: baseline_tuning_8in_64hidden_2layers_0drop
frames_in: 8
frames_out: 15
layers: 2
hidden_size: 64
dropout: 0.0
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.04304626657144178
- 0.020510417951530295
- 0.01794710834333791
- 0.013971202287681495
- 0.01197801097119345
- 0.010619537663186275
- 0.009996677678125569
- 0.009451639313910958
- 0.008956549441606938
- 0.008842225840810356
- 0.00853318296655824
- 0.008502209511927412
- 0.00848097200328602
- 0.008180334710197735
- 0.008180122003195029
- 0.008191777617210828
- 0.008031462006789596
- 0.007939562496222272
- 0.007549016748236705
- 0.007279005491092235
- 0.0070177631959602044
- 0.006808626583388335
- 0.006906505868640504
- 0.006778734075966515
- 0.006411409282561721
- 0.006228458820075928
- 0.0061240303506956825
- 0.006245162951040871
- 0.006105651112296913
- 0.006096146797431232
- 0.006067720683928155
- 0.005890836037365319
- 0.006033543960038054
- 0.005974741826494095
- 0.005888841931319124
- 0.005856030255178862
- 0.005779406108858087
- 0.005742627078124994
- 0.005910334106581875
- 0.005708197750669869
- 0.005731454575905883
- 0.0057806622537583865
- 0.005826568808642369
- 0.0058264185857216395
- 0.0058355095878809314
- 0.005845538461345095
- 0.0058525926728225965
- 0.0058674708515688585
- 0.005704677153873859
- 0.005683134651825398
- 0.005865675650678481
- 0.005763786167047823
- 0.00566801538431569
- 0.005773172094899265
- 0.00567339085443299
- 0.005706908797279377
- 0.005673260896619928
- 0.005649095642840183
- 0.005872286187154772
- 0.00577923848258355
- 0.0056820106427362075
- 0.005612762126175663
- 0.00563006481167542
- 0.005634773118845835
- 0.005669919791619612
- 0.005604274214327901
- 0.005663362906396955
- 0.005583670450067973
- 0.005556090991307474
- 0.005653853204007013
- 0.005656745918448778
- 0.005669629280868021
- 0.005586129719320732
- 0.005523156781409738
- 0.005611405130239982
- 0.0056137251137178155
- 0.005660104084924995
- 0.005621477772917928
- 0.005493069966500507
- 0.005558880143268387
- 0.005521700832450503
- 0.005441784257470052
- 0.0054510507874096495
- 0.005510667150345029
- 0.005442693903217021
- 0.005440878042291048
- 0.005459260092340881
- 0.005539793008348987
- 0.005506267927327677
- 0.005387120196430744
- 0.005372358960559285
- 0.005400043204898322
- 0.005380017588598819
- 0.005315039636968057
- 0.00547635053649922
- 0.005382751285605416
- 0.005387369133649936
- 0.005354853314524398
- 0.0053971860457588975
- 0.0052951801998564335
