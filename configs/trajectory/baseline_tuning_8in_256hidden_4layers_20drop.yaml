name: baseline_tuning_8in_256hidden_4layers_20drop
frames_in: 8
frames_out: 15
layers: 4
hidden_size: 256
dropout: 0.2
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.043925390036517305
- 0.023264386467164076
- 0.02269980858398389
- 0.020455032080128978
- 0.01793485407163448
- 0.016611071951875958
- 0.014601507294875912
- 0.013369802173368538
- 0.012742441230088095
- 0.0126911380882316
- 0.012485460590429698
- 0.012686714889552397
- 0.012378215978417215
- 0.012195420121373255
- 0.012191173314010794
- 0.01215629874952609
- 0.01211684462437524
- 0.012276179740747696
- 0.011870545158280602
- 0.012009925026257959
- 0.01178821635467908
- 0.011890300007277652
- 0.011986158434537392
- 0.011882096057451224
- 0.011819943101911605
- 0.011802877700309964
- 0.011931724569324073
- 0.011893843100229395
- 0.011935806025668412
- 0.011820342309207102
- 0.011797833285895707
- 0.01165247496358956
- 0.011696280663998066
- 0.011828555961292756
- 0.011972231731478926
- 0.011776907953044658
- 0.011713029828535605
- 0.011758421830644336
- 0.011686475699932515
- 0.011762566157156908
- 0.011608033788779492
- 0.011602123627509875
- 0.011625645128137704
- 0.011697674240869812
- 0.011835290873541108
- 0.011673159720494023
- 0.011699418920457741
- 0.011701867332139725
- 0.0116674434983089
- 0.011527650718447528
- 0.011787202309439831
- 0.01179125879101361
- 0.011561729880403491
- 0.011626208684395385
- 0.011580187520837481
- 0.011736568163703137
- 0.011751021942288815
- 0.011659074226936584
- 0.011581391620720867
- 0.011603284385526859
- 0.011529400508520724
- 0.011643729620624947
- 0.011524477678858027
- 0.01162768157104714
- 0.011650775659452134
- 0.011657276998356551
- 0.011551026814864784
- 0.011751150087559526
- 0.011743164603610206
- 0.01176575443978551
- 0.0114968229745385
- 0.011709644765699212
- 0.01156295947966319
- 0.011473191106291135
- 0.011637588585667972
- 0.01154493769819412
- 0.011545807364856518
- 0.011586371196221702
- 0.011544213087969943
- 0.011679152604428273
- 0.011555809492268894
- 0.011569937526047984
- 0.011503117347631273
- 0.01173275313045405
- 0.011793778649283737
- 0.011611443348936264
- 0.011523669055085393
- 0.011477515071960567
- 0.011603906332173302
- 0.011619343422353268
- 0.011654723506373695
- 0.011623532735282861
- 0.011590901320163586
- 0.01161558921389942
- 0.011518621534297738
- 0.011577326615777197
- 0.011628416160569538
- 0.011482456869952664
- 0.011655290357627069
- 0.011563969834978823
