name: baseline_tuning_4in_256hidden_4layers_0drop
frames_in: 4
frames_out: 15
layers: 4
hidden_size: 256
dropout: 0.0
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.03372432992874104
- 0.020348524260852072
- 0.017754527395246206
- 0.016774756017566464
- 0.01632557855344113
- 0.015962671419536625
- 0.01604763142488621
- 0.016119071799847815
- 0.015511499027963038
- 0.015511984557465271
- 0.015420641232695844
- 0.015541669027304944
- 0.015211203917401073
- 0.01504206497590115
- 0.014561093745776165
- 0.01406924786437073
- 0.012726262418760194
- 0.012903635758032769
- 0.012236066404040213
- 0.01177105639865737
- 0.011868090414798554
- 0.011398389832013182
- 0.011598758617944923
- 0.011526339170005586
- 0.011405610531154606
- 0.011247193544275232
- 0.011544215579137759
- 0.01129563667891938
- 0.011177192815797932
- 0.011116070747605445
- 0.011232482671829653
- 0.011273677621818618
- 0.011428742543046858
- 0.011161663414289555
- 0.011209295257742021
- 0.011041327396890632
- 0.011100955980105532
- 0.011244724671367877
- 0.011068647336444738
- 0.011059630133303595
- 0.01112002980561904
- 0.010934453699047919
- 0.011166652917494009
- 0.011143907829889176
- 0.01096550780520947
- 0.010898283613776719
- 0.011242384901615205
- 0.011020742575235573
- 0.011077817046531924
- 0.011134757510857818
- 0.01105140561789826
- 0.010879269668855418
- 0.011006611209638693
- 0.011168173663778069
- 0.010874857430426795
- 0.011024773276100555
- 0.011283594367588743
- 0.010971402381489307
- 0.010912216509933825
- 0.01097996431161408
- 0.010840107842038075
- 0.010851013249959107
- 0.011087683086961876
- 0.010994245637392189
- 0.010800262205992584
- 0.010818871847687312
- 0.010805420859222427
- 0.010829225027312836
- 0.010919579235767876
- 0.010920568530298309
- 0.011082594087462367
- 0.010717127397426484
- 0.01080349352164769
- 0.010924257418531695
- 0.011011938196549446
- 0.010784067276773262
- 0.010920787897006965
- 0.010914302281575439
- 0.010968154537732954
- 0.010829981905120759
- 0.010774252637300962
- 0.010756146450193576
- 0.010725135351588696
- 0.010726872101472116
- 0.010957639497693307
- 0.010787551917917566
- 0.010786579254968667
- 0.010725962417775098
- 0.01070398769778326
- 0.010833050722233306
- 0.010998921135417472
- 0.010746979056915015
- 0.010868530358291335
- 0.010774041692737811
- 0.010673152708253007
- 0.010987764258903486
- 0.01098145888313467
- 0.010738224256783724
- 0.010907856540547477
- 0.010735204518071296
