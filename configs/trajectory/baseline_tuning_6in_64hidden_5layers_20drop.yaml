name: baseline_tuning_6in_64hidden_5layers_20drop
frames_in: 6
frames_out: 15
layers: 5
hidden_size: 64
dropout: 0.2
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.045094376103952526
- 0.023388124397024514
- 0.023516591044608504
- 0.023298162245191635
- 0.02334214027505368
- 0.023174274910707025
- 0.02348007329273969
- 0.023341956664808095
- 0.023186213290318846
- 0.02334319371730089
- 0.023410991509445013
- 0.023311295825988055
- 0.023280226811766624
- 0.02327438073698431
- 0.02321728568058461
- 0.023244083032477648
- 0.02313616523751989
- 0.02323856852017343
- 0.02350152898579836
- 0.023297583346720784
- 0.023267697996925563
- 0.023284768080338837
- 0.023163315292913468
- 0.02319729591254145
- 0.02324272736441344
- 0.02328491595108062
- 0.023111460031941533
- 0.023206432280130685
- 0.023269602051004767
- 0.023142395203467458
- 0.023192266817204654
- 0.023360092821531
- 0.023285319563001394
- 0.023204931686632336
- 0.023202438117004932
- 0.02325557223521173
- 0.023108204861637206
- 0.023264325922355056
- 0.023169445514213294
- 0.023124158498831093
- 0.023128834064118566
- 0.0231126589467749
- 0.023153064935468138
- 0.02316517863655463
- 0.023142778105102478
- 0.023091865633614362
- 0.023123465152457355
- 0.023220322176348417
- 0.023106666130479424
- 0.023139654495753347
- 0.023253223625943065
- 0.02317907982505858
- 0.023194769793190063
- 0.023104235366918146
- 0.02321329157566652
- 0.023144231317564844
- 0.02314286434557289
- 0.02316644797101617
- 0.02308970920275897
- 0.0231718237278983
- 0.023192734736949206
- 0.023172927694395183
- 0.023088155931327493
- 0.023104589607100934
- 0.023112463764846325
- 0.023199191270396113
- 0.023065299179870637
- 0.02331069379579276
- 0.02319857933325693
- 0.023117736750282347
- 0.023118964734021575
- 0.02318204480689019
- 0.023145552584901453
- 0.023256514279637486
- 0.023116181371733546
- 0.02312965227756649
- 0.02316368978936225
- 0.02315188691718504
- 0.023156125179957597
- 0.02309340371284634
- 0.023106146533973516
- 0.023144912824500354
- 0.023179436149075628
- 0.023079094430431723
- 0.023109969426877798
- 0.023131102952174843
- 0.023246469104196876
- 0.023118496872484684
- 0.02314053678419441
- 0.02305775403510779
- 0.023081741214264186
- 0.023143546003848315
- 0.02314681540010497
- 0.023101844801567496
- 0.02317895272281021
- 0.023087112826760858
- 0.0231276057776995
- 0.023102473490871488
- 0.023089929856359957
- 0.02311758657451719
