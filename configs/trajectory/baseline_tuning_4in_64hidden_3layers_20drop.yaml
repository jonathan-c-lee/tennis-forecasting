name: baseline_tuning_4in_64hidden_3layers_20drop
frames_in: 4
frames_out: 15
layers: 3
hidden_size: 64
dropout: 0.2
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.040602642479410145
- 0.02072406707354534
- 0.017276374956615912
- 0.016135157637850003
- 0.015231281840874826
- 0.013654249202873971
- 0.012658374522019315
- 0.01250513429167094
- 0.012631186962495615
- 0.01263775513794871
- 0.011971508848400396
- 0.01173335746689527
- 0.011913143983685676
- 0.011708960822426978
- 0.011349421063507045
- 0.011321664460141349
- 0.010816788369858707
- 0.010514793653087115
- 0.010275537096377876
- 0.009481817978307789
- 0.009433419955319461
- 0.009347345950196923
- 0.009083753744899123
- 0.009283911097610805
- 0.00889544024557611
- 0.009386015389068627
- 0.008744858849195786
- 0.00878864140422256
- 0.00869065260997525
- 0.008515591853884634
- 0.00853980810921869
- 0.008732074279522087
- 0.008811817648188199
- 0.008652374855484124
- 0.00843158005564301
- 0.008463326260953405
- 0.008480110550644222
- 0.00879098453708453
- 0.008546514976999642
- 0.008286801873947735
- 0.00864689919039791
- 0.008143898289374731
- 0.008447719323966239
- 0.008730464425213911
- 0.008283476500461498
- 0.008319192433752764
- 0.008119448559519685
- 0.008364546262187722
- 0.008240765627519584
- 0.008278856082692927
- 0.008220301274164224
- 0.008266498030013876
- 0.008409111312142125
- 0.00815947530331251
- 0.00790216521371478
- 0.008137165333063882
- 0.008033105683869418
- 0.008183984143406521
- 0.008270298866670073
- 0.008106648007890693
- 0.008188631161357518
- 0.008104854660039698
- 0.008081215008357425
- 0.008097527675146673
- 0.008029765403473083
- 0.008152711906550843
- 0.008111807011803727
- 0.008047980457590318
- 0.007926848383597385
- 0.0077856226341315995
- 0.007933601397837017
- 0.008205401234006808
- 0.00806363153754285
- 0.00801360207023444
- 0.007934436650463828
- 0.0078066877595344445
- 0.0081087484392395
- 0.007892633966503687
- 0.008336046929068771
- 0.007993136860292268
- 0.008012194525634434
- 0.007839582975447915
- 0.007794629454750706
- 0.007798711435846341
- 0.007840072281980588
- 0.007925673968584082
- 0.008105137684371001
- 0.007745892516578789
- 0.007683850773092773
- 0.007780565466317866
- 0.007767036798651572
- 0.007777551648977362
- 0.007930598911587839
- 0.007845477540229942
- 0.007770400310372129
- 0.0076104638994567925
- 0.007764128036797047
- 0.007561970318173185
- 0.007663702092098969
- 0.0077191897391997
