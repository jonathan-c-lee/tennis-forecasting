name: baseline_tuning_6in_256hidden_5layers_40drop
frames_in: 6
frames_out: 15
layers: 5
hidden_size: 256
dropout: 0.4
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.033673123363405465
- 0.023721373314037918
- 0.023560251877643167
- 0.023530581942759456
- 0.023477527988143267
- 0.023398213740438222
- 0.023508838983252643
- 0.023551929113455116
- 0.02335123224183917
- 0.023313332884572446
- 0.023452012822963296
- 0.023347915324848145
- 0.023265043296851216
- 0.02325396069791168
- 0.023229339497629554
- 0.023297973605804146
- 0.023266898561269046
- 0.023205109720584004
- 0.023240197903942317
- 0.023151135793887077
- 0.023187763092573734
- 0.02318424538243562
- 0.023160282557364555
- 0.023324519791640342
- 0.023192662780638786
- 0.02335919919423759
- 0.023249374493025242
- 0.023193655419163406
- 0.023214737244416028
- 0.02310590213164687
- 0.023213939066044985
- 0.02321221341844648
- 0.023118831822648643
- 0.02322443361626938
- 0.02323019311297685
- 0.023323003971017896
- 0.02317842796910554
- 0.023235021787695587
- 0.023220174585003407
- 0.023207468260079623
- 0.023187589435838162
- 0.023192475130781532
- 0.023250724514946343
- 0.023187205172143878
- 0.02327728723175824
- 0.023256551451049746
- 0.023176958551630378
- 0.023159679397940634
- 0.023109340912196786
- 0.023193375789560378
- 0.02324752719141543
- 0.023251726082526146
- 0.023236167430877686
- 0.02322881801519543
- 0.023268223647028206
- 0.023231064225547014
- 0.02311533784959465
- 0.02331593760754913
- 0.0231391588691622
- 0.023240505787543952
- 0.02323675840161741
- 0.023112554964609445
- 0.02321059985551983
- 0.023368386505171656
- 0.023232974531129002
- 0.02314507691189647
- 0.02318591489456594
- 0.023143765714485197
- 0.023172416747547685
- 0.023195094859693198
- 0.02322557158768177
- 0.02318802399095148
- 0.02328386965673417
- 0.023158165055792778
- 0.0231807763222605
- 0.0231246636249125
- 0.02316436101682484
- 0.02310114910360426
- 0.023149175615981222
- 0.02316682394593954
- 0.023256825190037488
- 0.02317123709945008
- 0.023100921954028308
- 0.02314536916092038
- 0.023120526876300573
- 0.023127458081580697
- 0.023189745505806058
- 0.023105482826940714
- 0.023283469828311355
- 0.02314536552876234
- 0.02326253600185737
- 0.023152009258046745
- 0.02312664904166013
- 0.02324114562943578
- 0.023205146996770055
- 0.023312511667609215
- 0.02319286826532334
- 0.0230720934108831
- 0.02311265217140317
- 0.02315505996812135
