name: baseline_tuning_8in_128hidden_3layers_20drop
frames_in: 8
frames_out: 15
layers: 3
hidden_size: 128
dropout: 0.2
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.03803536291175251
- 0.02095366188006688
- 0.017659772941960566
- 0.014346569080990327
- 0.011810553431086526
- 0.010965095974410637
- 0.010192272624684662
- 0.010002653367958868
- 0.009747966882312976
- 0.009600031684754016
- 0.009623272309103344
- 0.008946676166798872
- 0.009074547233743758
- 0.008904555335027885
- 0.008747404152409563
- 0.008717453007032222
- 0.008797429826204912
- 0.008558922565153127
- 0.008241280488952805
- 0.008366525332337315
- 0.008051294780371688
- 0.007822418049025007
- 0.007503920741662194
- 0.007554564489452522
- 0.0072319431914181645
- 0.007171025983046127
- 0.007255359753211842
- 0.007121131519633758
- 0.007048203692406039
- 0.006796375989819629
- 0.0068191729273788535
- 0.006875160026446551
- 0.006616715763259349
- 0.00684237053405635
- 0.0067037755764926535
- 0.0072299234268455945
- 0.0066845313987777205
- 0.0066057707601568745
- 0.006452830337412372
- 0.006608434292617478
- 0.006980184282918897
- 0.006417081325869017
- 0.006677575586245784
- 0.006755660264458083
- 0.00644200088904251
- 0.00652732825661196
- 0.006450071362071211
- 0.0064445498423014265
- 0.006358992791722847
- 0.006357335408890172
- 0.006772725719109743
- 0.00636939001210694
- 0.0067484292166331145
- 0.006401795829068633
- 0.006280921558743414
- 0.006379935984747319
- 0.006556181057320931
- 0.006517281440452118
- 0.006326220074927882
- 0.006388472870605279
- 0.006338711863360073
- 0.006488367835578474
- 0.006447741862009221
- 0.006339715239650841
- 0.006499879987603879
- 0.006349780086923061
- 0.006370528182604268
- 0.006294874450828456
- 0.006248400629132609
- 0.00621908245891144
- 0.006371617234677453
- 0.006345469884786613
- 0.006283885660828857
- 0.006339949591061737
- 0.0062835284190464625
- 0.006099228694139025
- 0.006308903062975482
- 0.006355972771969022
- 0.0063201255029468216
- 0.006404363408779042
- 0.006284662710997878
- 0.006296253332844641
- 0.006206731927946587
- 0.006409074910739555
- 0.0063485031287315525
- 0.006241774475319853
- 0.006231437619964156
- 0.006251839243017043
- 0.006219908279732247
- 0.006113603274939181
- 0.006265865526857633
- 0.0061853445176318095
- 0.006317058298147366
- 0.0063746419169385974
- 0.00627309347420365
- 0.006235103149415005
- 0.006163501151236175
- 0.006224208390575987
- 0.006310653153665458
- 0.006175711824664775
