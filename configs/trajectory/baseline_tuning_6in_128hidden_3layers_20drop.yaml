name: baseline_tuning_6in_128hidden_3layers_20drop
frames_in: 6
frames_out: 15
layers: 3
hidden_size: 128
dropout: 0.2
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.038174016680568454
- 0.02068870518123731
- 0.018410044605843723
- 0.01576971698086709
- 0.013489256042521446
- 0.012736697308719158
- 0.011459708964684978
- 0.01070516150793992
- 0.009884944395162165
- 0.010019048070535063
- 0.01000368362874724
- 0.009545144950971007
- 0.00926325045293197
- 0.009205555089283734
- 0.008840172213967889
- 0.009426984022138641
- 0.00893033315660432
- 0.008687334810383618
- 0.008761719049653038
- 0.008892614400247112
- 0.008531684934860095
- 0.008576629200251772
- 0.00849802679149434
- 0.008293067279737443
- 0.008460471325088292
- 0.008225400722585619
- 0.008457606873707845
- 0.008355321874842048
- 0.008195897878613323
- 0.008204978489084169
- 0.008132878842297941
- 0.008118957845726981
- 0.008167262544156983
- 0.008084756130119785
- 0.007928904012078419
- 0.007964689593063668
- 0.008009804977336898
- 0.007786165218567476
- 0.008048639737535269
- 0.007939178636297584
- 0.0077788780617993325
- 0.007795454032020643
- 0.007736988354008645
- 0.00769173227599822
- 0.007805642142193392
- 0.007473950035637245
- 0.007644942391198129
- 0.00769972950220108
- 0.007494226942071691
- 0.0074822838068939745
- 0.007487422815756872
- 0.007448369613848626
- 0.007323085318785161
- 0.007511602976592258
- 0.007455403107451275
- 0.007246030762325972
- 0.007253113819751888
- 0.007350851118098944
- 0.007425810385029763
- 0.007138499297434464
- 0.007201530202291906
- 0.006910468975547701
- 0.0068605172506067905
- 0.006972247548401356
- 0.0068499943823553625
- 0.006663175008725375
- 0.006780946539947763
- 0.006733369483845309
- 0.006485103670274839
- 0.006630196960759349
- 0.006584134936565534
- 0.00656636186176911
- 0.0065532268374226986
- 0.006610283142072149
- 0.006466886808630079
- 0.00646555197017733
- 0.006474421685561537
- 0.006295192803372629
- 0.006560336577240378
- 0.0064613808528520165
- 0.006490645097801462
- 0.006442886951845139
- 0.006250696670031175
- 0.006451223319163546
- 0.006387298286426812
- 0.006259687797864899
- 0.006375045765889808
- 0.006421257031615823
- 0.006313928312738426
- 0.00641856329748407
- 0.006524338654708117
- 0.00632860743207857
- 0.006300197285600007
- 0.0061720870609860866
- 0.006382822163868695
- 0.00629404226783663
- 0.0062098978436551985
- 0.006231707881670445
- 0.00627972322399728
- 0.006239869588171132
