name: baseline_tuning_6in_256hidden_2layers_20drop
frames_in: 6
frames_out: 15
layers: 2
hidden_size: 256
dropout: 0.2
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.0326809131889604
- 0.016691641276702286
- 0.01335219843313098
- 0.012822565191891044
- 0.011207042576279492
- 0.01040214097010903
- 0.00955654343124479
- 0.009242442483082414
- 0.009337281761690974
- 0.00892834349651821
- 0.008787314250366763
- 0.008385567110963166
- 0.008582758501870558
- 0.008334517758339644
- 0.008504111622460186
- 0.008335906453430653
- 0.008399250369984656
- 0.008409935288364067
- 0.008114521007519216
- 0.008109064440941439
- 0.007930333027616143
- 0.00806281857076101
- 0.007870700175408274
- 0.007758574816398323
- 0.007929566473467275
- 0.007900189590873196
- 0.007622164039639756
- 0.007655105006415397
- 0.007625783450203016
- 0.007489242980955169
- 0.007496954017551616
- 0.007652843079995364
- 0.007584911270532757
- 0.00762147936038673
- 0.007522994460305199
- 0.007447157299611718
- 0.007285251270513981
- 0.0073888319195248185
- 0.0074404149781912565
- 0.0072489763493649665
- 0.00752951874746941
- 0.007185159291839227
- 0.007537640741793439
- 0.007274581864476204
- 0.007147499214624986
- 0.007186521484982222
- 0.0073634757311083375
- 0.007066977431531995
- 0.007107289030682295
- 0.00714711711043492
- 0.007125823484966531
- 0.00701086082844995
- 0.00682335055898875
- 0.006854766307515092
- 0.006753152067540213
- 0.006740767628070898
- 0.006686165946302935
- 0.006483199045760557
- 0.00668364523735363
- 0.006528677430469543
- 0.006411005614791065
- 0.006367145164404064
- 0.006622728158254177
- 0.006494729133555666
- 0.006375975179253146
- 0.006501249584835023
- 0.0064480723813176155
- 0.006344272004207596
- 0.006291568838059902
- 0.006727621663594618
- 0.006268198223551735
- 0.006417122518178076
- 0.006420018314383924
- 0.006296711027971469
- 0.006492314458591863
- 0.00641821941244416
- 0.006400154728908092
- 0.006706026563188061
- 0.006215918410453014
- 0.0062846779881510885
- 0.006051245596609078
- 0.006383105012355372
- 0.0062223417044151574
- 0.006175542855635286
- 0.006351730873575434
- 0.006438426516251638
- 0.006410596412024461
- 0.006243133987300098
- 0.006180529575794935
- 0.005984404802438803
- 0.006104670878266915
- 0.006250572577118874
- 0.006213570715044625
- 0.006194352760212496
- 0.006110299550346099
- 0.006115482497261837
- 0.006148258273606188
- 0.006073862023185939
- 0.006091394450049847
- 0.00616471046814695
