name: baseline_tuning_8in_128hidden_5layers_40drop
frames_in: 8
frames_out: 15
layers: 5
hidden_size: 128
dropout: 0.4
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.036630742487650886
- 0.02332070897793091
- 0.023416889194823518
- 0.02335414848042817
- 0.02349162308051239
- 0.023281406611204147
- 0.023427005715762513
- 0.023270621990101246
- 0.02336488807974737
- 0.023198709952868993
- 0.023213681635222857
- 0.023226108449169353
- 0.02326552698365118
- 0.02324179425552676
- 0.02312662485468237
- 0.023260381119915203
- 0.023060122021485732
- 0.02307922230396844
- 0.023166531685126734
- 0.023178916471668438
- 0.023011828289379047
- 0.023056028575836857
- 0.023079204019394856
- 0.023177502606111237
- 0.02310957196109657
- 0.023171675521173055
- 0.02305878997084838
- 0.023036368874998034
- 0.023065380693142172
- 0.02309704629727934
- 0.023103628366525415
- 0.023008686431412455
- 0.02306432904133314
- 0.02305754663163348
- 0.02307544619175075
- 0.02314973101491415
- 0.023142100630115858
- 0.023085239272611805
- 0.02309601063120969
- 0.023032140340420264
- 0.0230477980892115
- 0.023063427721492096
- 0.02303874954769883
- 0.023061097399154795
- 0.02304173915210781
- 0.023087970440900777
- 0.02300350745267506
- 0.023026120259509057
- 0.02308287088393788
- 0.02303585417191439
- 0.0230897107880704
- 0.022974138218862346
- 0.02314508029648775
- 0.02307922265763524
- 0.023042096933232076
- 0.023121855740400054
- 0.022986232833583142
- 0.023006825837530668
- 0.023005684484032136
- 0.02301199776650984
- 0.023063808137291593
- 0.023037467705958253
- 0.023061254639414292
- 0.022963929992121986
- 0.023057407805625395
- 0.023069866343483895
- 0.023101873365761357
- 0.023048440843254706
- 0.023027983564836315
- 0.023057318940947327
- 0.023003363286298286
- 0.02300055407553534
- 0.022984074063221865
- 0.02302636138953363
- 0.02300925140233734
- 0.023090669130788572
- 0.02298627392966536
- 0.023027009778667853
- 0.022993052731963653
- 0.023039876471591902
- 0.02298466627827928
- 0.022972323330520076
- 0.023049133629361285
- 0.02299957468964254
- 0.023003756481258176
- 0.023022348591704156
- 0.022999885209093365
- 0.02298934750636167
- 0.023000691557609584
- 0.0230304713278443
- 0.023090971315491805
- 0.022990371583949162
- 0.023068328706335416
- 0.023075329422762123
- 0.02299391743550195
- 0.023048499092176745
- 0.023044893918912623
- 0.023122086755554133
- 0.023008062563176397
- 0.023001547171911108
