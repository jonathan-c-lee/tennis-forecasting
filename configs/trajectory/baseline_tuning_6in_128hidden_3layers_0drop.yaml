name: baseline_tuning_6in_128hidden_3layers_0drop
frames_in: 6
frames_out: 15
layers: 3
hidden_size: 128
dropout: 0.0
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.038143081776797774
- 0.02062693127663806
- 0.018777520046569407
- 0.015157569432631135
- 0.014039106306154282
- 0.0130438361200504
- 0.012192275206325575
- 0.010444991663098336
- 0.00976522647542879
- 0.009353258268674836
- 0.008956586330896243
- 0.008538604440400378
- 0.008806497929617763
- 0.008447539625922217
- 0.008779703045729548
- 0.008569375221850351
- 0.008334971260046587
- 0.007972834288375452
- 0.008074854681035503
- 0.00789006192353554
- 0.007836581394076347
- 0.007763257616898045
- 0.007861118530854583
- 0.007770025258651003
- 0.007995941472472623
- 0.007738538162084296
- 0.00807554881903343
- 0.007755266246385872
- 0.007683237484889105
- 0.00787035885732621
- 0.00766471559763886
- 0.007653277582721785
- 0.007810012483969331
- 0.007602253596996888
- 0.007699998241150752
- 0.007494473119731992
- 0.007587967038853094
- 0.007501081499503926
- 0.007514561392599717
- 0.00760499999159947
- 0.007456152664963156
- 0.007381868542870507
- 0.007536131469532847
- 0.007478804275160655
- 0.007345835771411657
- 0.007420486328192056
- 0.007423999719321728
- 0.007364615221740678
- 0.007298452197574079
- 0.0072309360140934585
- 0.007199418888194487
- 0.00743456773343496
- 0.0075061530340462925
- 0.0072263721958734095
- 0.007491765031591058
- 0.007379209739156067
- 0.007473953283624724
- 0.00731282455381006
- 0.007238944829441607
- 0.007227285276167094
- 0.007302997726947069
- 0.00722769916174002
- 0.007220730831613764
- 0.007117631693836302
- 0.0071514903451316055
- 0.007082268287194893
- 0.007008612621575594
- 0.0070128157385624945
- 0.0071236675255931916
- 0.007045069691957906
- 0.006974271879880689
- 0.007203959545586258
- 0.00702226628200151
- 0.007075819437159225
- 0.006955817097332328
- 0.006947611935902387
- 0.006861519103404134
- 0.006728670670418069
- 0.006783487374195829
- 0.006593174481531605
- 0.006345948422676884
- 0.0062075464200461285
- 0.0061849409074056895
- 0.006008311032201163
- 0.0061368294700514525
- 0.005901809022179805
- 0.005875515690422617
- 0.005860692157875746
- 0.005824022379238158
- 0.0058976180094759915
- 0.005752407992258668
- 0.005728665291098878
- 0.005822662229184062
- 0.005800068777170963
- 0.005778911741799675
- 0.005646609730320051
- 0.005678690451895818
- 0.005724001149064861
- 0.005582525217323564
- 0.0056799984507961195
