name: baseline_tuning_6in_64hidden_4layers_20drop
frames_in: 6
frames_out: 15
layers: 4
hidden_size: 64
dropout: 0.2
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.049439886072650555
- 0.02312872011680156
- 0.02202233162242919
- 0.019025396660435945
- 0.0177610844373703
- 0.01715859166579321
- 0.01653473001206294
- 0.01571124718757346
- 0.014904573385138065
- 0.01348103021737188
- 0.012767359509598463
- 0.01314128537196666
- 0.01286982570309192
- 0.012412826402578504
- 0.01245530836749822
- 0.012104828178416937
- 0.01221602427540347
- 0.011950910155428573
- 0.012000049056950957
- 0.012139759142883122
- 0.01202189697069116
- 0.0120864886790514
- 0.011905936413677409
- 0.011745524156140164
- 0.011883311008568853
- 0.011957178002921865
- 0.012034345360007137
- 0.011758385074790568
- 0.012110593856777995
- 0.011767658562166616
- 0.011785949335899205
- 0.01169363675871864
- 0.01171185345738195
- 0.01152255583438091
- 0.011635607277275995
- 0.011707039864268154
- 0.011556086980272084
- 0.011786513112019748
- 0.011607131350319832
- 0.011599452793598175
- 0.01162013408029452
- 0.01148467553430237
- 0.01149216711637564
- 0.011530976684298366
- 0.011531942966394126
- 0.011551604839041829
- 0.011546708340756596
- 0.011432753020199016
- 0.011721479392144829
- 0.011668154480867087
- 0.01149796859244816
- 0.011639587581157684
- 0.011665252293460071
- 0.01160433815093711
- 0.01142840608372353
- 0.011408775235759094
- 0.011603648972231895
- 0.011310099239926786
- 0.011633106344379484
- 0.01141390647389926
- 0.01152555252192542
- 0.011454897309886292
- 0.011491209850646555
- 0.011488434544298797
- 0.011375202500494197
- 0.011382955993758515
- 0.011327825050102547
- 0.011549619934521615
- 0.0115139244007878
- 0.011342296336079017
- 0.011415225500240923
- 0.011451729742111639
- 0.011529821751173586
- 0.011409425485180692
- 0.011470617668237537
- 0.011406494263792411
- 0.011443876952398568
- 0.011259125877404585
- 0.011387839505914599
- 0.011297281144652515
- 0.011543722526403144
- 0.011411653715185821
- 0.011339403386227787
- 0.011459100653883069
- 0.011355251795612276
- 0.011489035532576963
- 0.011300677538383753
- 0.011359868838917464
- 0.011453705694293603
- 0.011233245668699965
- 0.011457744566723705
- 0.011482826538849623
- 0.01134383473545313
- 0.011422246164875105
- 0.011352073721354827
- 0.011259538953891025
- 0.011404821946052834
- 0.011350518878316507
- 0.011488287610700355
- 0.011516248120460659
