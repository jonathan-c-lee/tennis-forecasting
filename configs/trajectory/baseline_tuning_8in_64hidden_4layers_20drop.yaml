name: baseline_tuning_8in_64hidden_4layers_20drop
frames_in: 8
frames_out: 15
layers: 4
hidden_size: 64
dropout: 0.2
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.044309825978324384
- 0.023014222342473797
- 0.021788973420198206
- 0.019734065024818802
- 0.018642231091102468
- 0.017265059890909287
- 0.015165152865214438
- 0.013571875853629052
- 0.013425387182756316
- 0.0132710011440176
- 0.012956266055661666
- 0.01294821802573868
- 0.012802724431775794
- 0.012564655016117457
- 0.012573026886940756
- 0.012350648287919503
- 0.012274913136151772
- 0.01233061063515989
- 0.012170514221527155
- 0.012275466589327854
- 0.012475461722646334
- 0.012250455791908728
- 0.012102669517545007
- 0.011853780957009596
- 0.012126504938719394
- 0.011832527303478764
- 0.011880756155410899
- 0.011782441960199725
- 0.011684325735874568
- 0.011727316316830206
- 0.01179024680293625
- 0.012076892724991599
- 0.01163981406348227
- 0.011590947939342336
- 0.01182326551856874
- 0.011587975747128831
- 0.011674175145033794
- 0.011690423782631944
- 0.011608556184116044
- 0.011666784257498345
- 0.01165860313686389
- 0.011650318822151498
- 0.01154069080241496
- 0.01149093099174243
- 0.011707713933590847
- 0.011533543096171528
- 0.011560784428840197
- 0.011633358406539581
- 0.011631191295536258
- 0.011552633918067323
- 0.011365823141193087
- 0.011473005277965265
- 0.011605226470133926
- 0.011540815422806558
- 0.011462729960632852
- 0.01150988002861791
- 0.011467475892056394
- 0.011432599288093138
- 0.011494203594430714
- 0.011494951051530203
- 0.011435411033468157
- 0.01145755115283441
- 0.011445768590120576
- 0.011368351905972143
- 0.011311384648839129
- 0.011361000646801688
- 0.01145492199383959
- 0.011438227176100393
- 0.011624125628201644
- 0.011323089357701283
- 0.011383976339350772
- 0.011504888681907065
- 0.01136194575059263
- 0.01135191748130925
- 0.011401189833030671
- 0.011353048342692702
- 0.011372988801921093
- 0.011359854176923444
- 0.011412698492596421
- 0.011347298233333645
- 0.011636839596012348
- 0.011555826863203245
- 0.011437399348220493
- 0.011389201436238953
- 0.011286178126318169
- 0.011417637885654275
- 0.011329421991647421
- 0.011278386192419861
- 0.011408657507522952
- 0.011411935969291232
- 0.011495397013576724
- 0.01123680964206593
- 0.011320462532907347
- 0.011317860635728398
- 0.011301427873299469
- 0.011319495401569183
- 0.011282170651174045
- 0.011301705755199058
- 0.011389088828729677
- 0.011417860636794114
