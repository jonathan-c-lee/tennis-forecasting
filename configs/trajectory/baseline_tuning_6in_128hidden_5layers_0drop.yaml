name: baseline_tuning_6in_128hidden_5layers_0drop
frames_in: 6
frames_out: 15
layers: 5
hidden_size: 128
dropout: 0.0
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.04035504143685102
- 0.02374365699943155
- 0.023362620477564634
- 0.023395900160539895
- 0.02329310110071674
- 0.023868872202001512
- 0.023336202395148574
- 0.023418252682313324
- 0.023275620490312576
- 0.023340173717588186
- 0.02337297627236694
- 0.023416476300917567
- 0.023294899775646628
- 0.023474657069891693
- 0.023442839493509383
- 0.023238720919471233
- 0.02340227102395147
- 0.02323568464489654
- 0.023530052183195947
- 0.023250540252774954
- 0.023453361191786825
- 0.023185685405042022
- 0.02341558572370559
- 0.023175648122560233
- 0.0233642342267558
- 0.023095740331336857
- 0.023227547039277853
- 0.023192981898318976
- 0.02321334625594318
- 0.02315638973377645
- 0.02322536746505648
- 0.023207647702656688
- 0.023252501082606614
- 0.023120849998667835
- 0.02328889344353229
- 0.02319028484635055
- 0.02315308803226799
- 0.0231614085030742
- 0.023085496632847934
- 0.023106055182870476
- 0.02316400974523276
- 0.023230748262722044
- 0.023214581375941633
- 0.023205721005797385
- 0.023105581302661448
- 0.023208791960496456
- 0.023261014046147464
- 0.023083462682552635
- 0.023116512305568902
- 0.023132105357944965
- 0.02319232024019584
- 0.023150989948771895
- 0.023210306314285844
- 0.0231169106438756
- 0.02322452418738976
- 0.0231787339085713
- 0.0231344067142345
- 0.023160032811574638
- 0.023142075922805816
- 0.023132621811237188
- 0.02313436029944569
- 0.023120479239150882
- 0.02313995878212154
- 0.023147802567109466
- 0.02320811356185004
- 0.023131819977425038
- 0.023142126633320003
- 0.02309901223052293
- 0.023113728454336523
- 0.023186613619327546
- 0.023129089386202395
- 0.023156715743243694
- 0.023202029522508383
- 0.02316413129447028
- 0.023179253446869552
- 0.0231037909979932
- 0.023154308425728232
- 0.023157485108822585
- 0.023118276172317563
- 0.023457993869669735
- 0.023174040671437978
- 0.02309260438196361
- 0.02308090776205063
- 0.02317582203540951
- 0.02308043767698109
- 0.023105789453256875
- 0.02316681034862995
- 0.023171364050358533
- 0.023109454521909358
- 0.02318448827136308
- 0.02316974988207221
- 0.023050568718463182
- 0.023140895855613054
- 0.023160869569983332
- 0.02321513609495014
- 0.02309948831098154
- 0.023187077045440672
- 0.023112891998607665
- 0.023195285815745592
- 0.02315376091282815
