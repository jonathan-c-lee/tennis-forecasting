name: baseline_tuning_8in_256hidden_3layers_20drop
frames_in: 8
frames_out: 15
layers: 3
hidden_size: 256
dropout: 0.2
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.030543886195821098
- 0.01830134569089624
- 0.014502812554187413
- 0.011522602219181725
- 0.01160725781434699
- 0.01047103987016444
- 0.010195613591165482
- 0.009847040895278318
- 0.009642536103536811
- 0.00920300909518441
- 0.00930926578025086
- 0.009038779130087623
- 0.008901333294903176
- 0.008952658823868143
- 0.008831112698616483
- 0.008889573160558939
- 0.008698441235560782
- 0.008586035210261994
- 0.008309137877784197
- 0.00805236442792642
- 0.007649166332675686
- 0.007588978591551886
- 0.007615101346863976
- 0.0074441937281738355
- 0.007195210001796861
- 0.0074150861075878895
- 0.00718035979220007
- 0.007205880135061998
- 0.007077264063107439
- 0.006954385091468126
- 0.00698546264202723
- 0.006817967866700661
- 0.0070859249268623095
- 0.007104383799235655
- 0.0065983450217054615
- 0.006824876918587126
- 0.00699906242728422
- 0.007095785286937711
- 0.006927859568614749
- 0.006854858314264802
- 0.0066317560275002746
- 0.006675839312138814
- 0.006671629268440265
- 0.006560641267230805
- 0.00676138193900638
- 0.006655463577495723
- 0.006402166990586851
- 0.006610296324744255
- 0.006549623323297954
- 0.006683845394232039
- 0.006536858120956753
- 0.006368868465570709
- 0.006688443319046799
- 0.0064812127995905995
- 0.006387125405989871
- 0.00644218681462675
- 0.0068244410154138565
- 0.0065016680562137805
- 0.006439840583177873
- 0.006546607759745815
- 0.00646402497622597
- 0.006564382563899213
- 0.006527944686056315
- 0.006560461283248814
- 0.0062807165705186276
- 0.006626637652516365
- 0.006389617489627268
- 0.006448509336649617
- 0.0062848915157344525
- 0.0065076960121057455
- 0.006325635864529051
- 0.0063866795677267295
- 0.006372390975114666
- 0.00650877152463492
- 0.006548910180719782
- 0.006356409152592474
- 0.0066170686962012245
- 0.0063054839921289985
- 0.006407521113965519
- 0.006278680720001082
- 0.006250362996530684
- 0.006343407662514644
- 0.006307573482111285
- 0.006425867122421159
- 0.0063332755802364285
- 0.0064288104318459575
- 0.006417493518630538
- 0.006288059951761101
- 0.006351568008171795
- 0.006234685961109928
- 0.0064171510218065
- 0.006130766462463933
- 0.006324698768343918
- 0.006366084913334138
- 0.006274150537114732
- 0.006231422541969562
- 0.006375395893296109
- 0.006331241306483369
- 0.0062150975536036344
- 0.006228759563586946
