name: baseline_tuning_4in_64hidden_3layers_0drop
frames_in: 4
frames_out: 15
layers: 3
hidden_size: 64
dropout: 0.0
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.044505082777942774
- 0.021269742192493543
- 0.01732692268481593
- 0.015638359661363524
- 0.01390822464025315
- 0.013061887895067533
- 0.012887394400658432
- 0.012305423111459355
- 0.012141305677316807
- 0.012012279230273433
- 0.011778808463318849
- 0.01214190690352777
- 0.011477214715409058
- 0.010980098266844396
- 0.01050039974650667
- 0.010002711529119147
- 0.009078309578062207
- 0.008882265290774313
- 0.008536458458107563
- 0.008268906096755355
- 0.008356419800102342
- 0.008382708972526921
- 0.008035645762711395
- 0.00798537036013088
- 0.007994614363314561
- 0.007967142391099054
- 0.007682279856116684
- 0.007853067250071484
- 0.0076045495469445066
- 0.007668496408488279
- 0.00800152722010274
- 0.007611778116336575
- 0.007476028537860623
- 0.007526460856797151
- 0.007440725841593963
- 0.007606304492111559
- 0.00763011965210791
- 0.007355325130952729
- 0.007511223482404962
- 0.0073313427525629965
- 0.0074115085335057455
- 0.0072680751557381434
- 0.007354633888390697
- 0.007218517294084585
- 0.007371272500834347
- 0.0072838055303343285
- 0.007303080504277238
- 0.007233342857180554
- 0.007296235047648718
- 0.007139578726096654
- 0.0075201221948696505
- 0.007413339438951678
- 0.007118929746664233
- 0.007264978332835951
- 0.007136447717332178
- 0.007229323981812707
- 0.007131248292869624
- 0.0072280315762776656
- 0.007164472622084029
- 0.007022629204539605
- 0.007011218421897034
- 0.007005319298233515
- 0.007166107484128004
- 0.00719331435997177
- 0.007167456119700715
- 0.0070070963421905485
- 0.0070119581794665185
- 0.007087199333595273
- 0.007075019111787832
- 0.007153113550839968
- 0.006969688310759303
- 0.007068926600716364
- 0.007101698140441267
- 0.0070991375840004575
- 0.007077672277335767
- 0.007102013462119632
- 0.0069992975446821
- 0.007030020904853756
- 0.006933322481029195
- 0.006993798119372424
- 0.007104685380594966
- 0.006925153201101003
- 0.007001449831152036
- 0.00702066455082393
- 0.006991585707981829
- 0.006929043280880576
- 0.006945876588608011
- 0.007038328325214945
- 0.007001239964508532
- 0.006944520421970038
- 0.0069215209395797166
- 0.00712968339499684
- 0.006959928763041526
- 0.006940049182531642
- 0.0069491125493781804
- 0.0069771993928301485
- 0.006883477987606584
- 0.00689859725649894
- 0.006961320981061385
- 0.0069849063975759495
