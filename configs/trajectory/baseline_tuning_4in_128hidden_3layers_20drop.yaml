name: baseline_tuning_4in_128hidden_3layers_20drop
frames_in: 4
frames_out: 15
layers: 3
hidden_size: 128
dropout: 0.2
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.03928951912180141
- 0.020237883736873852
- 0.017007139706869186
- 0.014303317684450267
- 0.013403022052421247
- 0.013261719681552531
- 0.013109378516674042
- 0.012757178539709176
- 0.012238959689843065
- 0.01213746786945396
- 0.012037364340582748
- 0.011670562231706249
- 0.011685961121578275
- 0.011621049766279297
- 0.01129245010699019
- 0.010680333446757293
- 0.010341237327888792
- 0.009755369224068191
- 0.009614424233865222
- 0.009668122660828593
- 0.009314782687543351
- 0.009101944946810419
- 0.009098838117939455
- 0.0091584684373236
- 0.008918488662643933
- 0.009026084917333022
- 0.008823813715328773
- 0.009064601142143395
- 0.00900517108010841
- 0.00874139290348983
- 0.008624801969868534
- 0.00896231843917458
- 0.008890422520998083
- 0.008623700310119692
- 0.0086434811503155
- 0.008695598662957365
- 0.008763704908850752
- 0.008679528737923613
- 0.00853150469009523
- 0.008623334412451512
- 0.008490067156445649
- 0.008469887876906146
- 0.008363146378003337
- 0.008257375276980944
- 0.00837996618155344
- 0.008346056398924119
- 0.00845259298099044
- 0.008260222410576211
- 0.00835236578742847
- 0.00820923063122196
- 0.008198451722201742
- 0.008182527606639966
- 0.008221350506775908
- 0.00829805384884462
- 0.008363105356693268
- 0.007961079035598187
- 0.00799741338432571
- 0.008318535052239895
- 0.008090512988008098
- 0.008067914342254769
- 0.008134319544712335
- 0.007965738873606847
- 0.008118877750763923
- 0.00791705315242763
- 0.008081006305867139
- 0.007943814240947918
- 0.008081252393485219
- 0.008023104061269097
- 0.008071708582042729
- 0.007966601445029179
- 0.007925012982507914
- 0.008043230373274398
- 0.008152263911647929
- 0.007972812550257386
- 0.007891721097913421
- 0.0081054767317794
- 0.008066773937762152
- 0.007878632209965108
- 0.00791490370016775
- 0.007686671407111449
- 0.008074700872609277
- 0.007929315077669826
- 0.007933920910466968
- 0.007902191141275343
- 0.007883279446374488
- 0.007926492526391406
- 0.007831554445955489
- 0.007797061551914171
- 0.007946438006596801
- 0.007955769674829494
- 0.008017369080334902
- 0.007825149763605477
- 0.007939949726547909
- 0.008180193660527836
- 0.008012303645596092
- 0.007832739996597355
- 0.00772815183908851
- 0.007650207843125602
- 0.008015345546336454
- 0.0078861054757403
