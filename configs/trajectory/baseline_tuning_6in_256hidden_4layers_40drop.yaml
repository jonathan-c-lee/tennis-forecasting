name: baseline_tuning_6in_256hidden_4layers_40drop
frames_in: 6
frames_out: 15
layers: 4
hidden_size: 256
dropout: 0.4
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.040925837284885344
- 0.023277541727293283
- 0.021085593348834662
- 0.018476142617873847
- 0.017606496694497764
- 0.016753417684230953
- 0.01650326270610094
- 0.015524001303128898
- 0.013948063785210251
- 0.013597842829767615
- 0.013383514306042343
- 0.012836728652473539
- 0.013071859476622195
- 0.012819996988400816
- 0.01261547066969797
- 0.012787524971645325
- 0.013025865564122796
- 0.012410792673472315
- 0.012456339865457267
- 0.012530017714016139
- 0.012500474107218907
- 0.012938686576671899
- 0.012411128298845142
- 0.012254270468838513
- 0.012430657842196524
- 0.012372497771866619
- 0.012364304525544868
- 0.012467872200068087
- 0.012532710039522499
- 0.012522640835959465
- 0.012210919242352247
- 0.01237532813102007
- 0.012406276777619496
- 0.012160181376384572
- 0.01241044100606814
- 0.0122387717012316
- 0.012324088567402214
- 0.012247706472408026
- 0.012374385457951576
- 0.012498620949918405
- 0.012241248646751047
- 0.012082908232696355
- 0.012228579062502831
- 0.012119815812911838
- 0.012036704953061417
- 0.012119801144581287
- 0.01208224666188471
- 0.012210089527070523
- 0.012370140117127448
- 0.012019399576820433
- 0.01209750542184338
- 0.012235833192244172
- 0.012080172589048744
- 0.012073804327519611
- 0.012230885023018345
- 0.01197894411161542
- 0.0123023723019287
- 0.011952061392366885
- 0.012318815826438368
- 0.012186541478149593
- 0.012046059349086136
- 0.012056973256403581
- 0.011980832554399967
- 0.012046531960368156
- 0.011882546631386503
- 0.012092100630979985
- 0.012018103495938704
- 0.011912997614126652
- 0.01204487459617667
- 0.011880723654758184
- 0.012291556573472917
- 0.011842508695553988
- 0.012065408163471148
- 0.01217507878318429
- 0.012033064820570871
- 0.011998392222449184
- 0.012051755998982117
- 0.01221161795547232
- 0.011991806922014802
- 0.012002571241464467
- 0.011975625064224005
- 0.012155434023588896
- 0.012078255118103698
- 0.012001193017931655
- 0.01187832219293341
- 0.011979073355905711
- 0.011850922706071288
- 0.01200200876337476
- 0.012187737534986809
- 0.0120752954040654
- 0.011805254442151636
- 0.01187394242733717
- 0.01215713213896379
- 0.012120151636190712
- 0.012093911785632372
- 0.012214732368011027
- 0.011942138866288587
- 0.012125044025015085
- 0.011943242338020355
- 0.011944199725985528
