name: baseline_tuning_8in_256hidden_3layers_40drop
frames_in: 8
frames_out: 15
layers: 3
hidden_size: 256
dropout: 0.4
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.04256276423229447
- 0.021760530934869488
- 0.01987944628241696
- 0.017158444216357
- 0.013867069165446336
- 0.011824301408627365
- 0.011178040847512363
- 0.010773065334916869
- 0.010295243532974509
- 0.01079579123260477
- 0.009850243259740026
- 0.009649663774555997
- 0.009570218740573412
- 0.009909552127075723
- 0.009429265509206282
- 0.009526979514173691
- 0.009399308333809994
- 0.009035826354181464
- 0.00874235937253961
- 0.008734226356484468
- 0.008546904566450209
- 0.008463817383339511
- 0.008440182113996412
- 0.00786249704446785
- 0.008119584680122287
- 0.007757565548902825
- 0.007566021696393249
- 0.007433673478898745
- 0.007364442566103196
- 0.007711182613680257
- 0.007148210183257544
- 0.00734334907647741
- 0.0072486909412885015
- 0.007079417787822364
- 0.007180575505370581
- 0.007179331871433349
- 0.007117394181086293
- 0.007100715083836378
- 0.007048982195556164
- 0.0069691069435941265
- 0.007023936791840611
- 0.0070308431204927115
- 0.0069938420341644865
- 0.007131353053087487
- 0.0066749524808477
- 0.006805382274044088
- 0.006775869760968828
- 0.006760435119931457
- 0.006941159332430438
- 0.006979358995545514
- 0.006884982143351926
- 0.006696726870428347
- 0.006907962598613923
- 0.006915994990569881
- 0.006759768534640345
- 0.007016940431409999
- 0.006639866258571797
- 0.00679566040399331
- 0.006709616212763741
- 0.006738184635892887
- 0.006699890240178078
- 0.00674922519681763
- 0.006810382724727822
- 0.006614044674118108
- 0.0067397660245718085
- 0.006684259075341346
- 0.006724467386102564
- 0.006638014806976802
- 0.0065874883174141755
- 0.006763564776393432
- 0.006758594838312909
- 0.006712465125572266
- 0.006723294600467139
- 0.006692852860293056
- 0.006937441893534947
- 0.006608615499697154
- 0.006772286989549293
- 0.006598653289477659
- 0.006755690656225138
- 0.006569890552966655
- 0.006697477985031997
- 0.006524579092577289
- 0.006671096127527424
- 0.006627215968468521
- 0.006509506541504701
- 0.006724727617081584
- 0.006652612958244885
- 0.006571904225628587
- 0.006475785113517431
- 0.006528283033189895
- 0.00637435538199129
- 0.006773363622023335
- 0.006716409659814797
- 0.006501667558133036
- 0.006612700118412134
- 0.006514409244579228
- 0.006694220760955086
- 0.006656274906819379
- 0.006471510720144533
- 0.006612116317677347
