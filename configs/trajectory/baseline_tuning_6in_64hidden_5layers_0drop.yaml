name: baseline_tuning_6in_64hidden_5layers_0drop
frames_in: 6
frames_out: 15
layers: 5
hidden_size: 64
dropout: 0.0
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.04371593976393342
- 0.023244961095042527
- 0.023462091071996836
- 0.02322120781755075
- 0.023338967305608093
- 0.023212234186939896
- 0.023370816244278104
- 0.02330155512318015
- 0.023301097680814564
- 0.02327604591846466
- 0.023249105201102793
- 0.023218066978733985
- 0.023413998971227555
- 0.023174262489192188
- 0.02331809966126457
- 0.023256028431933373
- 0.023338433634489775
- 0.023212635307572782
- 0.023181594663765282
- 0.023223259835503995
- 0.023398123565129936
- 0.023232217179611325
- 0.023155772069003433
- 0.02316715836059302
- 0.023250708263367413
- 0.023226978187449277
- 0.023229099332820625
- 0.023214248241856694
- 0.02311776193091646
- 0.023208417079877107
- 0.023125231824815275
- 0.023210271052084862
- 0.02317621677648276
- 0.02313453326933086
- 0.02313495852285996
- 0.023204822291154413
- 0.023179755848832428
- 0.023212763690389694
- 0.023180143139325083
- 0.02317003288771957
- 0.023161120875738562
- 0.023188016284257172
- 0.02321794831659645
- 0.023206980805844067
- 0.023316441848874093
- 0.02319320241222158
- 0.023093481885734946
- 0.02326482773059979
- 0.023248764709569512
- 0.023102080426178874
- 0.023127580736763777
- 0.023087780456990004
- 0.02311204911675304
- 0.023187696584500372
- 0.023172118526417762
- 0.02322347169974819
- 0.023162401001900434
- 0.023259497620165347
- 0.02319597763707861
- 0.02311166049912572
- 0.023167331900913267
- 0.02319026197073981
- 0.023221609485335647
- 0.023199630505405366
- 0.023117808194365354
- 0.0232021821080707
- 0.023081238754093646
- 0.023093959118705244
- 0.02327308157691732
- 0.023246215016115457
- 0.023154908954165877
- 0.02313420355785638
- 0.02315553923835978
- 0.023209649114869536
- 0.023165104538202287
- 0.023193377058487386
- 0.023174575180746615
- 0.023134337924420833
- 0.02318780714413151
- 0.02315011724131182
- 0.023095581494271756
- 0.02310938489390537
- 0.023172911955043674
- 0.02311779682058841
- 0.023055957828182726
- 0.023099146969616412
- 0.023114179261028767
- 0.023086936096660793
- 0.02312810654984787
- 0.02315226614009589
- 0.023071703664027155
- 0.023089197021909057
- 0.023124981881119312
- 0.023104985267855226
- 0.02308405318763107
- 0.023118616291321815
- 0.02318151092622429
- 0.02320755956461653
- 0.02307865528855473
- 0.023123186139855534
