name: baseline_tuning_4in_256hidden_5layers_0drop
frames_in: 4
frames_out: 15
layers: 5
hidden_size: 256
dropout: 0.0
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.03713059323023499
- 0.023443949753763498
- 0.0237321437302011
- 0.02415422541031867
- 0.023371050950645664
- 0.023750804272698767
- 0.02349059751694217
- 0.023706796475582652
- 0.02344432558266469
- 0.0237164375613685
- 0.02335101102743252
- 0.023294790601932708
- 0.02362537868090986
- 0.023282949318304474
- 0.023561719471565736
- 0.02339230480109468
- 0.02316061907482368
- 0.0232470351167851
- 0.023673734271231994
- 0.023451365507495256
- 0.02338912419652865
- 0.023233441429005727
- 0.02331997067840011
- 0.023445461186821812
- 0.02337292819801304
- 0.023327378027233076
- 0.023329204983181424
- 0.023602011314604755
- 0.023207710193539108
- 0.02347005450707159
- 0.02340858788401992
- 0.02318894285938622
- 0.02326900616610124
- 0.023160220698717936
- 0.02314703289511395
- 0.02323581279473908
- 0.023348083236703166
- 0.023254895778257907
- 0.02334176843273051
- 0.0231597881856156
- 0.02319026306087588
- 0.023264085667000875
- 0.023343863356628535
- 0.023299877313368113
- 0.02329310710415428
- 0.023278888636901054
- 0.0231783506632955
- 0.023412207015042687
- 0.023356148444208098
- 0.023214825371533264
- 0.023286284154487982
- 0.0233084006625929
- 0.023332795611134282
- 0.023127451883973898
- 0.02322417309070811
- 0.023233080892191258
- 0.023395913710564743
- 0.023114248822776625
- 0.023321705582885096
- 0.02323947107580341
- 0.0233566458394498
- 0.0232427668194344
- 0.023330027145552046
- 0.02320440298659198
- 0.023457411515675944
- 0.023236212079171783
- 0.02324444733928015
- 0.023317710737939232
- 0.023188551266988117
- 0.023143666439954146
- 0.02330380194119097
- 0.023265311954382025
- 0.023300439337797373
- 0.023543359642779385
- 0.023281199340191152
- 0.023270102229291274
- 0.023515263744802388
- 0.023292750338621347
- 0.023216511387331985
- 0.02332600351009104
- 0.023279811727044023
- 0.023229438800042794
- 0.023163514901642448
- 0.023283684913666895
- 0.02339510096490015
- 0.023179180414220433
- 0.023167854128980342
- 0.023124015418651663
- 0.02321267539612305
- 0.02319783117208216
- 0.02323516090343028
- 0.023074404968891616
- 0.02324573077077483
- 0.023275935263545426
- 0.023092786930961375
- 0.02354364502991055
- 0.023475066804683503
- 0.023221825640418647
- 0.023243554718332525
- 0.023144680845700663
