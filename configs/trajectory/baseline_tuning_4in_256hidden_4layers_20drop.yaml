name: baseline_tuning_4in_256hidden_4layers_20drop
frames_in: 4
frames_out: 15
layers: 4
hidden_size: 256
dropout: 0.2
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.03611011623784348
- 0.02257556314177719
- 0.01917910471236632
- 0.016949521504158592
- 0.01629314678548663
- 0.01628456030178953
- 0.01616163963428986
- 0.0165084571129194
- 0.01590278083573521
- 0.01578232442477235
- 0.016006944867793794
- 0.015864569992746835
- 0.01587115596106023
- 0.015484801516580729
- 0.01520764761040976
- 0.014990662948952781
- 0.015289188926050693
- 0.014724873615727748
- 0.014206936847372556
- 0.013887678583463034
- 0.013268131440804328
- 0.013109972539507313
- 0.012980985823144883
- 0.01285995863791969
- 0.012586709359131846
- 0.012337987242197548
- 0.012614142816559768
- 0.012081427654872337
- 0.012113655963337716
- 0.012231054715812206
- 0.012131121009588242
- 0.012356284971314448
- 0.012237949434805799
- 0.012204088690334264
- 0.012017130736767509
- 0.012049580832230455
- 0.011880840042628993
- 0.011788401798701581
- 0.01186629010502387
- 0.012225863408803203
- 0.011881196032059782
- 0.011874715101985652
- 0.012130602952782754
- 0.011779835453417934
- 0.011823460833387978
- 0.011973448477133556
- 0.01217873061052811
- 0.011694380375384181
- 0.01214863756602561
- 0.01198341933734439
- 0.012094861505852069
- 0.011872852933995518
- 0.011863865935600099
- 0.011976935831760918
- 0.011945651326742437
- 0.01177961485069475
- 0.011629190531639773
- 0.011884009718527029
- 0.011858541828890642
- 0.011781801676584614
- 0.011749201138032439
- 0.011983139101231907
- 0.011813455715453551
- 0.011943041714897126
- 0.01180990835375808
- 0.0117500635024942
- 0.011825608612716566
- 0.011740990759183964
- 0.011798484032444748
- 0.011853834481932867
- 0.011669610753471468
- 0.011861550081291316
- 0.011870519511033724
- 0.011824700211025314
- 0.011805040163942326
- 0.011639035071165841
- 0.011907394061347953
- 0.011818192514050523
- 0.011734737462743564
- 0.011685889547713746
- 0.011710946448147297
- 0.011903554913990292
- 0.01180068470744623
- 0.011663535592594632
- 0.011775271392162934
- 0.011909050441542526
- 0.011887311843442327
- 0.011894752501429599
- 0.011697213797841543
- 0.01177877036532686
- 0.011739845071447852
- 0.01162793198140499
- 0.011823957860699775
- 0.011743499920416026
- 0.011839307327237394
- 0.011789879169499065
- 0.011603024776703046
- 0.011662555709021328
- 0.011610890422476294
- 0.011722273837177105
