name: baseline_tuning_4in_64hidden_3layers_40drop
frames_in: 4
frames_out: 15
layers: 3
hidden_size: 64
dropout: 0.4
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.049727095658948395
- 0.021730138103903077
- 0.019389557686668855
- 0.016501132433337194
- 0.01588094961128117
- 0.013853475026050468
- 0.013394320119218326
- 0.013093609598545749
- 0.012677460012060625
- 0.01276153614629566
- 0.012615103654011531
- 0.01224210299551487
- 0.012240777200340856
- 0.012077153016479663
- 0.011999696682862661
- 0.011709682476695306
- 0.011725797461644734
- 0.011240478760252396
- 0.011066835994521776
- 0.010608431193287726
- 0.010419161886804633
- 0.010209793138697191
- 0.010445199320437732
- 0.00961397726226736
- 0.009619805335216685
- 0.009413945103455106
- 0.009527361578089588
- 0.009285273007404657
- 0.009426162641403484
- 0.009152514601333274
- 0.009301916862849468
- 0.009066644297153861
- 0.009351161159115074
- 0.009102475881162617
- 0.009130465062220155
- 0.008854368437127566
- 0.00880676011244456
- 0.009013076657774273
- 0.009051357539669598
- 0.008840763245789725
- 0.009073143934164151
- 0.008856096989072767
- 0.008750266113812908
- 0.008917563169458766
- 0.008776163912297767
- 0.008651651332821742
- 0.008655301140000423
- 0.00897068931594675
- 0.008531398858507106
- 0.008624567667505256
- 0.008833185763868653
- 0.008908578890295308
- 0.008905122533762529
- 0.008634536567339559
- 0.008714899644945507
- 0.008467106200340722
- 0.00866307064683901
- 0.008571730725421214
- 0.008544292369926418
- 0.008473163528114926
- 0.008617917759872881
- 0.008702135685095449
- 0.008614655124184526
- 0.008355953339717271
- 0.008412541580145006
- 0.00859621754720991
- 0.008502834528270695
- 0.008327221635867047
- 0.008520353085326927
- 0.008315129153844383
- 0.008477907081675014
- 0.008334549724549792
- 0.008411009859201717
- 0.008318496868014336
- 0.008274598541543072
- 0.008245348527935552
- 0.008400289870706606
- 0.008247641895403281
- 0.008251371063338018
- 0.008210928627738246
- 0.008213463130142585
- 0.00821948466523562
- 0.008191062028255359
- 0.008101326568673054
- 0.008144562966247767
- 0.008120318943703617
- 0.008330596950089123
- 0.008560119357741909
- 0.008125505950531842
- 0.008133727511000118
- 0.0081959849074023
- 0.008144903795816649
- 0.008110008420951572
- 0.008103623353864676
- 0.008344583564012506
- 0.008210298340813613
- 0.008033111530505581
- 0.008042819194357705
- 0.008264050974200169
- 0.008261874858519914
