name: baseline_tuning_8in_64hidden_3layers_20drop
frames_in: 8
frames_out: 15
layers: 3
hidden_size: 64
dropout: 0.2
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.044584334497870526
- 0.021054418934391268
- 0.018924469257928903
- 0.016180670831965494
- 0.014290080169993865
- 0.011964767817643624
- 0.010930794267620466
- 0.010222519783279564
- 0.010102436695059266
- 0.009444482783680852
- 0.009554446816350086
- 0.00951407836820883
- 0.009180886871358263
- 0.009108897728869055
- 0.009042217867755437
- 0.008822474440064612
- 0.008855326112972784
- 0.009042862537493812
- 0.008666735496136207
- 0.008689767958101216
- 0.008557013831325348
- 0.008599446980353398
- 0.008485708462333754
- 0.008458072284260128
- 0.008488141424671004
- 0.00825720163698815
- 0.008162795112150002
- 0.008163581896997705
- 0.007861265529512981
- 0.007878091044818299
- 0.007858696788596579
- 0.007440131599720143
- 0.007179987386953604
- 0.007117706180043235
- 0.0072909290136038505
- 0.007421797984338637
- 0.007062027613997836
- 0.00691385904645335
- 0.007046009325481291
- 0.006840789189585779
- 0.006922070532329852
- 0.006915786506938217
- 0.006873192053429688
- 0.006597051261393707
- 0.006648581504491689
- 0.006787899858023547
- 0.006704157990509573
- 0.006849851706831516
- 0.006798006461556011
- 0.006458609247037881
- 0.006626828620799735
- 0.006590354704309868
- 0.00661621274591624
- 0.006952106357328122
- 0.00645049943152485
- 0.006615889768552365
- 0.006410733472461565
- 0.006403850102679262
- 0.006690492847627854
- 0.006445876918025786
- 0.006359190727242186
- 0.006385805480229326
- 0.006328144334728205
- 0.006389083202244549
- 0.006464228623464138
- 0.006341437104782915
- 0.006220904293859118
- 0.006425043612223448
- 0.006273975539834628
- 0.006356574527188381
- 0.006510013773377183
- 0.00633137082221293
- 0.006381209609629233
- 0.006268561030797
- 0.006488800838683979
- 0.006446341998710097
- 0.00620564907388408
- 0.006270791062071354
- 0.0062789550121826465
- 0.006070365701931753
- 0.006064193452932412
- 0.006248184173261818
- 0.006477445596829057
- 0.006293567428011683
- 0.006187605827787443
- 0.006144682246059934
- 0.006201119294767327
- 0.006253563955166861
- 0.006271281276676285
- 0.006100028756227863
- 0.006337221723662902
- 0.006171044905351687
- 0.00613480808119042
- 0.0062462984867205345
- 0.006256780130317128
- 0.00616731604301854
- 0.006171859606298842
- 0.006180275576424938
- 0.006143061656363403
- 0.006121031356433147
