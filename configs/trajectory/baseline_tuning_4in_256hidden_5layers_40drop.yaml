name: baseline_tuning_4in_256hidden_5layers_40drop
frames_in: 4
frames_out: 15
layers: 5
hidden_size: 256
dropout: 0.4
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.034519407633738015
- 0.023697630191842716
- 0.023605746297556678
- 0.023750698584833262
- 0.023636268934717885
- 0.023578892829885453
- 0.023525791932587272
- 0.023504753079679277
- 0.023636314718995566
- 0.023311279760098752
- 0.02359220589062682
- 0.02353961763466582
- 0.02341920363912244
- 0.02334283335985225
- 0.023694638645759335
- 0.02323654640098045
- 0.023550541910492342
- 0.023288728692281394
- 0.023257501204900534
- 0.02345912843758677
- 0.02358546689796595
- 0.023461752950593277
- 0.023187260591873416
- 0.023484589187083422
- 0.02333925675922706
- 0.023658548550749267
- 0.023478295608067218
- 0.023412621729535822
- 0.023359993104765445
- 0.02329760390897224
- 0.02327353997087037
- 0.023190159787550384
- 0.023331186504183726
- 0.023349342810243
- 0.023426546726697757
- 0.0233197645916615
- 0.023233515543886172
- 0.023304307039965083
- 0.023258746199217844
- 0.023237719028084365
- 0.023372580929670806
- 0.023279529225863058
- 0.02323032405089449
- 0.02323796502371997
- 0.0232114707476195
- 0.02327272359189796
- 0.023482861411240365
- 0.02337774031876046
- 0.02328228799879183
- 0.02316165107221883
- 0.02347686631536042
- 0.023103275761744122
- 0.023277791906838066
- 0.02336696411172549
- 0.023196391059936566
- 0.023331421266459387
- 0.023187567721362465
- 0.023257201204053415
- 0.023114451161229316
- 0.0234438528502245
- 0.023266846934954327
- 0.02319981303801875
- 0.023212013835156406
- 0.02341848615281008
- 0.023250299827828082
- 0.023278566997176335
- 0.02329849037859175
- 0.023358376489745244
- 0.023493822388075018
- 0.023280100712989582
- 0.02309460230861549
- 0.02340045713900048
- 0.023349937476953606
- 0.023391873771209777
- 0.023154135701465017
- 0.023291960289632832
- 0.023344998523868895
- 0.02318567021485464
- 0.02330920346265222
- 0.02327593011252674
- 0.023268077258066632
- 0.023388550858254784
- 0.023288403580218185
- 0.02316137974690876
- 0.023383022400975964
- 0.023196333467408462
- 0.023369620853092198
- 0.02317555149856173
- 0.023171189402080614
- 0.023265000018808577
- 0.023242779719976733
- 0.023368812212145623
- 0.023247332680096596
- 0.023130256084748255
- 0.023158385475844513
- 0.02325214075361505
- 0.023158752819362246
- 0.023710315828614027
- 0.02325848494598895
- 0.02347006313042876
