name: baseline_tuning_8in_64hidden_2layers_20drop
frames_in: 8
frames_out: 15
layers: 2
hidden_size: 64
dropout: 0.2
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.044234208078889906
- 0.020293443888142894
- 0.01877036169642889
- 0.014896978470909445
- 0.012947708050001271
- 0.010828438156013247
- 0.010184131014526268
- 0.009493207688667352
- 0.009417952114975528
- 0.009126277852662002
- 0.008953173102551623
- 0.008669687582392104
- 0.008997979149505307
- 0.009160855030523071
- 0.00826134623464527
- 0.00814556049866767
- 0.008123736793198917
- 0.007956129805291002
- 0.007720132641305652
- 0.007630205282917883
- 0.007371558577906859
- 0.007337471016364385
- 0.00710419619078689
- 0.006992847452388156
- 0.006890514452906349
- 0.006719469251936372
- 0.006598066355844465
- 0.006618274069285091
- 0.0066946570855812935
- 0.006367290637137581
- 0.006435691331855104
- 0.006338596234946877
- 0.006229639430589314
- 0.0061879612540802625
- 0.006213101702801223
- 0.006182432610871671
- 0.005983893143578987
- 0.006233443898042735
- 0.0061131268710228085
- 0.006126515685191638
- 0.006016607092740604
- 0.006121347732016746
- 0.005888918494286982
- 0.006030541635413147
- 0.005948359432594874
- 0.005993473384812285
- 0.005902077867118995
- 0.005931975546917772
- 0.005811356296880713
- 0.0059619082515186906
- 0.006022804569971713
- 0.0059075203895144444
- 0.005839485138701864
- 0.0057546787606434354
- 0.005871867649021405
- 0.005812153771307461
- 0.005778346582068296
- 0.005848222202916122
- 0.005791246077588088
- 0.005889329628995325
- 0.005777475506633143
- 0.005913686316719726
- 0.005840670709392127
- 0.0057224882442409855
- 0.005807747430745748
- 0.005698481615915706
- 0.005677640641438244
- 0.005813488680751452
- 0.005805521021608876
- 0.005781659051846666
- 0.005838766207777058
- 0.0057711056728340406
- 0.005705140165607386
- 0.005733974434176012
- 0.005708802394168098
- 0.0057640905385907696
- 0.00586389540694654
- 0.005636840534125325
- 0.005712215399628953
- 0.005787430787930572
- 0.00562193134764233
- 0.0056881735844042484
- 0.005623854369608851
- 0.005728375582213077
- 0.005729917958496681
- 0.005802260788416938
- 0.00571982348278825
- 0.005685473379643658
- 0.005615011912688047
- 0.0056660688877152865
- 0.005675444246823841
- 0.005559055889143219
- 0.00559927110819594
- 0.005575054658199602
- 0.005590380611534738
- 0.005715940401099528
- 0.005749093937463587
- 0.005524193051660174
- 0.0056836786738868
- 0.005603359629034619
