name: baseline_tuning_4in_128hidden_2layers_20drop
frames_in: 4
frames_out: 15
layers: 2
hidden_size: 128
dropout: 0.2
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.03595496996961258
- 0.019532512666450605
- 0.0151342194021484
- 0.013615590784652734
- 0.012682574076784981
- 0.01270696241983477
- 0.011917849243791015
- 0.011565726543604224
- 0.011682572101967202
- 0.011323259804213856
- 0.011171974644156885
- 0.010735331407897635
- 0.009874538397761408
- 0.009987970043755607
- 0.009231245116457159
- 0.008788046329339712
- 0.009139021427405102
- 0.008721038906110657
- 0.008524803875911015
- 0.008246403101279779
- 0.008324510929531154
- 0.008222786847639966
- 0.008155626618521816
- 0.00824734587567272
- 0.008117487378142498
- 0.00807600166004749
- 0.008042456547695177
- 0.008224677708413865
- 0.008122926894115446
- 0.007755737406788049
- 0.008081358759721487
- 0.00793398577535962
- 0.008072722458890007
- 0.007855070915855007
- 0.008080795775225132
- 0.007765754281232755
- 0.007802258472728692
- 0.007916374804659022
- 0.007757735910055078
- 0.007970079290968032
- 0.007880348827183983
- 0.007876974714483008
- 0.007996497089388195
- 0.007830840742422475
- 0.007627045790331416
- 0.00780982324094684
- 0.007630963988004275
- 0.007843976805883425
- 0.007763963620994746
- 0.007688150235256295
- 0.007581394642913415
- 0.007647344480372137
- 0.0075474276816771355
- 0.007472041126248645
- 0.007691134028941577
- 0.007615583178437787
- 0.007431406116710953
- 0.007525069871917367
- 0.0074748207964463
- 0.0074683211191936775
- 0.0075283495387361375
- 0.007576733149220178
- 0.0075811262322980685
- 0.007587228269304758
- 0.0076130671357667
- 0.007322543415666362
- 0.007432299493639557
- 0.007435292488446942
- 0.007675941504630042
- 0.007376530713597198
- 0.007384524807149981
- 0.007378195596421942
- 0.007678980283715107
- 0.007506931562804514
- 0.00731812849537366
- 0.007448041495395664
- 0.007400267481527946
- 0.007266985953865964
- 0.007335697944609471
- 0.007503910151160794
- 0.007432122461865713
- 0.00744342542954801
- 0.007279465423414001
- 0.007567675542776231
- 0.00754393527376247
- 0.007387746947553055
- 0.007393627444765082
- 0.007668924253479934
- 0.0074396896532472265
- 0.007268976247696964
- 0.007382845649794664
- 0.007177563461785515
- 0.007257045442123472
- 0.007250788368652632
- 0.00740847926310919
- 0.007293526773099546
- 0.007420599627320046
- 0.00729143315995181
- 0.007423177459219723
- 0.007419662492602695
