name: baseline_tuning_8in_128hidden_2layers_0drop
frames_in: 8
frames_out: 15
layers: 2
hidden_size: 128
dropout: 0.0
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.03751777086548413
- 0.018083171836465975
- 0.014468878967380977
- 0.011904681183963636
- 0.01029222196298121
- 0.009951342392382743
- 0.009370524424446535
- 0.009086552258769545
- 0.00889071704866954
- 0.009024763851178974
- 0.00844016614594037
- 0.008525348586749427
- 0.008218739093340274
- 0.00825372377198331
- 0.00808472715648292
- 0.007868034794596555
- 0.00820293741984458
- 0.0075781636022597175
- 0.00722726664942088
- 0.007224989984231659
- 0.0069701030402432515
- 0.0066601620291512975
- 0.0066355748832980285
- 0.006601833449558744
- 0.006585521078255924
- 0.006409400021893125
- 0.0062628380977843385
- 0.006419051014169862
- 0.006218665238186906
- 0.006105618468851228
- 0.006145053145275275
- 0.006421078948445524
- 0.005924728171475515
- 0.006062719010146735
- 0.005918975645393322
- 0.0061818964637910265
- 0.0060634412331200096
- 0.00597915007685653
- 0.005759029301425702
- 0.0059686118878329855
- 0.005927456713788495
- 0.005849748587565897
- 0.006023569666202875
- 0.005867430536500826
- 0.005777104831406776
- 0.0058522602024523515
- 0.006041834543494484
- 0.005780814171332536
- 0.005918551454485594
- 0.0057967446384880736
- 0.005777776306141404
- 0.0058827780694052385
- 0.005855331200328243
- 0.0057809883139178725
- 0.00566233518604142
- 0.005721939603880614
- 0.005740312605954801
- 0.005691452609092186
- 0.005755944407391775
- 0.0058398214994069145
- 0.005731848068535328
- 0.0056896631759178785
- 0.005613811172639267
- 0.005731925005800551
- 0.005630032524843759
- 0.005731604949135004
- 0.005751073204240278
- 0.005633749727961383
- 0.00555430574613753
- 0.005607071544833576
- 0.005589155713096261
- 0.005696388350540324
- 0.005748554560226164
- 0.005681208252340932
- 0.005503657486148273
- 0.005527297303056981
- 0.005716638032441275
- 0.005675584151515666
- 0.005580647315099081
- 0.005509068965440309
- 0.005698568603212509
- 0.00555689616388158
- 0.005630846562665663
- 0.005541283136257265
- 0.005602095025603341
- 0.005512054311111569
- 0.005477736032084573
- 0.005650867153949375
- 0.005527639867667156
- 0.005576457073794136
- 0.005465010148649917
- 0.0054630054119691445
- 0.005487450987949402
- 0.005460008377610128
- 0.005413773549201933
- 0.005373920835672489
- 0.005599298561581328
- 0.0056538326972270314
- 0.0054902856155664105
- 0.005444356019290377
