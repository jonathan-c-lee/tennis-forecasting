name: baseline_tuning_6in_128hidden_2layers_0drop
frames_in: 6
frames_out: 15
layers: 2
hidden_size: 128
dropout: 0.0
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.03588365479372442
- 0.01847034121165052
- 0.014450653037056328
- 0.013324164546793327
- 0.011936337721999734
- 0.010743442206876352
- 0.009503776562632993
- 0.009139476757263764
- 0.008952074818080292
- 0.008516648132354022
- 0.008517644065432251
- 0.008511695638298988
- 0.008354431402403861
- 0.008080995612544939
- 0.008145673671970144
- 0.00787823306163773
- 0.007765937939984724
- 0.007756307109957561
- 0.00781409427872859
- 0.007885877211811021
- 0.007604080549208447
- 0.0075265313091222195
- 0.007378675503423438
- 0.0073426572955213485
- 0.007625199103495106
- 0.007144692126894369
- 0.007302509399596602
- 0.007224676525220275
- 0.007101409754250198
- 0.007265802467009053
- 0.007183397770859301
- 0.006931939802598208
- 0.006726477009942755
- 0.006760314997518435
- 0.006713528375257738
- 0.006426661490695551
- 0.006219056411646306
- 0.006212116195820272
- 0.006176904472522437
- 0.006144837662577629
- 0.005992640284239315
- 0.006131549619021825
- 0.005910923413466662
- 0.005933591222856194
- 0.006045617934432812
- 0.0058211173949530345
- 0.0058425068476935845
- 0.005836479982826858
- 0.005842088535428047
- 0.005865724774776026
- 0.0057781185576459395
- 0.005977932855603285
- 0.0057297486055176705
- 0.005812583322403952
- 0.005967883521225304
- 0.005684092943556607
- 0.005709485817351379
- 0.005682433146284893
- 0.005635890280245803
- 0.005828373649273999
- 0.005658109823707491
- 0.005682178042479791
- 0.005605305763310753
- 0.005698994037811644
- 0.005616525304503739
- 0.005663782745250501
- 0.005584167694905773
- 0.0057340025960002095
- 0.005652427146560513
- 0.005738920150906779
- 0.005645579434349202
- 0.005727629744797014
- 0.00572843074623961
- 0.005801498805521987
- 0.005451836815336719
- 0.005609653866849839
- 0.00553686338244006
- 0.0055420953663997356
- 0.00556915643683169
- 0.0055530184734379874
- 0.005511562930769287
- 0.0055569456977536905
- 0.005639200049336069
- 0.005474455069634132
- 0.005506710530607961
- 0.005442483490332961
- 0.0054687459283741194
- 0.005488292232621461
- 0.0054341371287591755
- 0.005539695837069303
- 0.005624647150398232
- 0.005485304477042518
- 0.0055281054810620844
- 0.005432668013963848
- 0.00542361221741885
- 0.005464233993552625
- 0.00547921714023687
- 0.005512112326687202
- 0.005514612008119002
- 0.0054401199042331426
