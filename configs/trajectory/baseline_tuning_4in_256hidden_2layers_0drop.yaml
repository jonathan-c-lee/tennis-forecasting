name: baseline_tuning_4in_256hidden_2layers_0drop
frames_in: 4
frames_out: 15
layers: 2
hidden_size: 256
dropout: 0.0
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.03341778596564208
- 0.017749190560461564
- 0.013832276457069833
- 0.01251105345601653
- 0.012295335795684361
- 0.012014667905959082
- 0.011809288909267864
- 0.011440517283102244
- 0.010984735816349218
- 0.011115572513023645
- 0.010417537740719171
- 0.009631689390696493
- 0.009084548870170558
- 0.008932337481068609
- 0.008524863302339742
- 0.008703956018305488
- 0.008231330950411014
- 0.008325467162110188
- 0.008469478468652125
- 0.008044471441089739
- 0.007951413930888161
- 0.007828795121131856
- 0.008124146584628357
- 0.008027939568561168
- 0.007861548258612553
- 0.007910359300167105
- 0.0076620997286137235
- 0.0077091128346912655
- 0.008118403098189536
- 0.007873975326893505
- 0.007643287920933447
- 0.0077828908925531085
- 0.0073998990399694
- 0.007623144937104281
- 0.007527107545347126
- 0.0074019689647549835
- 0.007507016094700422
- 0.0075043189557798115
- 0.007485896090252532
- 0.007388194338820967
- 0.0071929428370002615
- 0.007413914102348097
- 0.007750166695059082
- 0.0071790690740777385
- 0.00716327898848204
- 0.007293860324554973
- 0.007198376420103473
- 0.007192570739138274
- 0.007180780235585975
- 0.007179934008299936
- 0.0071735075519730645
- 0.007111436037783638
- 0.00703202585839195
- 0.007268680248087571
- 0.007042296707952096
- 0.0069436603800658095
- 0.007057595411660495
- 0.007442022282860161
- 0.007126059417647344
- 0.007058405380604075
- 0.007086494414388765
- 0.007108798480512183
- 0.006962001375440095
- 0.006896091492869604
- 0.007086435082816967
- 0.007000242756610668
- 0.006980757453237419
- 0.006996092800464895
- 0.007104758230716358
- 0.006958853712098466
- 0.0069392619505064725
- 0.006941262463015722
- 0.006978239910102185
- 0.007009340950322372
- 0.00695971662270618
- 0.006860287992260706
- 0.006968534620547736
- 0.006940401952575754
- 0.006941743565861274
- 0.006827882301338293
- 0.00692320480528805
- 0.006749343109765538
- 0.006917823416491349
- 0.007009615989424932
- 0.006827889544958317
- 0.006917695730441698
- 0.006836553466402822
- 0.006971261912473926
- 0.00682737282189874
- 0.0069667331667410005
- 0.007069796662961627
- 0.006910567585792806
- 0.006977389762063085
- 0.006837839369926556
- 0.006872786967842667
- 0.006689456932499636
- 0.006830657136707026
- 0.006861054556973186
- 0.006899997051575302
- 0.0069162329014988595
