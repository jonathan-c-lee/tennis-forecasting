name: baseline_tuning_8in_64hidden_4layers_40drop
frames_in: 8
frames_out: 15
layers: 4
hidden_size: 64
dropout: 0.4
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.0439388818708779
- 0.023074603486287443
- 0.02262848094577276
- 0.020619683403851865
- 0.018679817678713347
- 0.017075524276381808
- 0.015494424413559558
- 0.01390443564852393
- 0.013659241821475421
- 0.013088488267569602
- 0.013012971033495439
- 0.01308854024480038
- 0.012988954971108255
- 0.012545403930111021
- 0.012276898409369626
- 0.012359740943471087
- 0.012349783136403258
- 0.012227996405732782
- 0.012128730888089424
- 0.011957132021743285
- 0.012119015395829949
- 0.01209406930764642
- 0.012048244523473932
- 0.011910696295856298
- 0.012031900295634059
- 0.011792522749002976
- 0.011932079061347096
- 0.011779715607673684
- 0.011963874019116541
- 0.011923478715876235
- 0.011746418839202652
- 0.011797835290007577
- 0.011721895111701157
- 0.011844788029601303
- 0.01180614051821677
- 0.011791397086521493
- 0.011842484774563131
- 0.011831428820290897
- 0.011786431787370504
- 0.011525104282117343
- 0.011724891105690334
- 0.011919906816763592
- 0.011592429997753116
- 0.011722332915833479
- 0.011797643514185012
- 0.01175798855344706
- 0.011654010419792768
- 0.011708077750628508
- 0.011774227636147149
- 0.011750199820233297
- 0.011717551293535322
- 0.011635542245982568
- 0.011623974146816549
- 0.011629388160720656
- 0.011564135109369137
- 0.011608939040216464
- 0.01163741050853948
- 0.011776242434648396
- 0.011683120781296416
- 0.011778236749947449
- 0.01179813656107157
- 0.01174316769819471
- 0.01170769971029102
- 0.01170297751580424
- 0.011817282920443936
- 0.011702297780002598
- 0.011743033658477325
- 0.011655604567001515
- 0.01183971306426993
- 0.01163938550773678
- 0.011833188748812373
- 0.011823261681283954
- 0.011728537209992167
- 0.01164030281921165
- 0.011750263710140804
- 0.011743881574631491
- 0.011503262810786313
- 0.011538768764821034
- 0.011557980334456963
- 0.011634801378874461
- 0.011625082503202596
- 0.011584376833767077
- 0.011527382986785113
- 0.011908062574559753
- 0.011633737089371756
- 0.011727488193000797
- 0.011601295864468888
- 0.011691231875904377
- 0.011672491431707822
- 0.011527607671303463
- 0.011694214613282983
- 0.011672955324661128
- 0.01161967231479438
- 0.011706900570683087
- 0.011768670057099832
- 0.011669035953811453
- 0.011608727070019592
- 0.011499367324234564
- 0.011624359136706666
- 0.011714719613141652
