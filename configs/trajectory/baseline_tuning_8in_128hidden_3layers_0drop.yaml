name: baseline_tuning_8in_128hidden_3layers_0drop
frames_in: 8
frames_out: 15
layers: 3
hidden_size: 128
dropout: 0.0
loss: MSE loss
optimizer: Adam
learning rate: 0.002
weight decay: 0.0001
epochs: 100
batch_size: 32
train loss:
- 0.03720114495652386
- 0.021288946813231784
- 0.018641765087937252
- 0.015148735157202315
- 0.012280819336353223
- 0.010918860954432926
- 0.010170435055477333
- 0.009602646791387963
- 0.009384878197849928
- 0.009443575480976437
- 0.009050921230470832
- 0.009005725931942085
- 0.008911675024966273
- 0.008688126690685749
- 0.008539847163129834
- 0.008579551118508548
- 0.008632508077057479
- 0.008377448260736994
- 0.008394977814647594
- 0.008090359282597333
- 0.00877748665553105
- 0.008342416055170419
- 0.008007584068971344
- 0.007803354099911603
- 0.007872366576302277
- 0.00789966817379375
- 0.007547582234432803
- 0.007258686926687443
- 0.006807155736215129
- 0.006641259758815735
- 0.006880202136132159
- 0.006443956852124273
- 0.006324713572246741
- 0.006257221857203713
- 0.0061495136292769184
- 0.006146077924301919
- 0.006189465811594
- 0.006332301334301128
- 0.006091847921474071
- 0.0059761966555084605
- 0.00608429555851919
- 0.006129783752103207
- 0.006026255072955089
- 0.0060501236503920225
- 0.006134559267754608
- 0.005936788669138958
- 0.006008888465128368
- 0.005938754190066004
- 0.005884480556543869
- 0.006079051894123984
- 0.005937188427565219
- 0.005998932057991624
- 0.0060975872646262756
- 0.005952552494392554
- 0.00599773572109451
- 0.005880068772460652
- 0.005787112646960193
- 0.005882023872005977
- 0.006018619050118554
- 0.005942036686583033
- 0.00580802031710178
- 0.005936962325432444
- 0.005821685498297403
- 0.005882254863582268
- 0.005834366787295741
- 0.005739336111288094
- 0.005868215558908974
- 0.005875095309501019
- 0.005860911190061819
- 0.00586631909731917
- 0.005741610392173634
- 0.005795433218414082
- 0.0058253644081422045
- 0.005847223595232714
- 0.0057725755651068834
- 0.005676646769942739
- 0.005847974297225098
- 0.005850501219989567
- 0.005682314209687182
- 0.005669036258271412
- 0.005697245450242411
- 0.0056876773780942715
- 0.005631913221735931
- 0.0056830777792566565
- 0.005776304557117857
- 0.005636203108661914
- 0.005681298357800026
- 0.005741516010293477
- 0.005793610794021737
- 0.005687121195789379
- 0.00560828064320774
- 0.0056267594388108464
- 0.005669863623437248
- 0.005592033688474117
- 0.005600506766946821
- 0.005573613554404317
- 0.0058536301543818245
- 0.0055396530388182475
- 0.005566108733109093
- 0.005599514834724272
